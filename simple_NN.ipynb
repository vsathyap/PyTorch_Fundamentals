{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHrePd7Hwr9fuGwvnm0I/2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vsathyap/PyTorch_Fundamentals/blob/main/simple_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tutorial 5: Create a basic Neural Network Model**"
      ],
      "metadata": {
        "id": "ut-U7YimJu_i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amuX3hCFJs29"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "#To use the neural network from torch\n",
        "import torch.nn as nn\n",
        "# To move our data forward\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Model Class that inherits nn.Module (using OOPs)\n",
        "class Model(nn.Module):\n",
        "  '''Input Layer (it has the 4 features of the IRIS dataset)\n",
        "  --> Hidden Layer 1\n",
        "  --> Hidden Layer 2\n",
        "  --> Output Layer (3 classes of the IRIS dataset)'''\n",
        "  # Constructor of the class\n",
        "  def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n",
        "    # Instantiate our nn.Module\n",
        "    super().__init__()\n",
        "\n",
        "    #Fully connected network\n",
        "    self.fc1 = nn.Linear(in_features,h1) # Input Layer --> H1\n",
        "    self.fc2 = nn.Linear(h1,h2) # H1 --> H2\n",
        "    self.fc3 = nn.Linear(h2,out_features) # H2 --> Output Layer\n",
        "\n",
        "  #Function to move everything forward\n",
        "  def forward(self,x):\n",
        "    #Using reLu (rectified Linear Unit), f(x) = max(0,x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "NPZn7ZswLQUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To keep the random number generator deterministic\n",
        "torch.manual_seed(41)"
      ],
      "metadata": {
        "id": "SZF8l2oCNOxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model\n",
        "model = Model()"
      ],
      "metadata": {
        "id": "jSgIzRXyNd4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tutorial 7 : Load the data and train the model**"
      ],
      "metadata": {
        "id": "VsjwiJumcuUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "3etoQ6qUN4Di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an url to load our data from\n",
        "url = 'https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv'\n",
        "my_df = pd.read_csv(url)\n",
        "my_df"
      ],
      "metadata": {
        "id": "6b32GHQFPSYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df.head()"
      ],
      "metadata": {
        "id": "0cZ7jVwaP1Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List the unique labels in species\n",
        "my_df['species'].unique()"
      ],
      "metadata": {
        "id": "94WoqbzuQec_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To replace the species with integers\n",
        "my_df['species'] = my_df['species'].replace('setosa',0.0)\n",
        "my_df['species'] = my_df['species'].replace('virginica',2.0)\n",
        "my_df['species'] = my_df['species'].replace('versicolor',1.0)"
      ],
      "metadata": {
        "id": "ZenF10N8P6mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df"
      ],
      "metadata": {
        "id": "QAiSgUiIQKNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Test Split\n",
        "X = my_df.drop('species',axis =1)\n",
        "Y = my_df['species']"
      ],
      "metadata": {
        "id": "CVooacxoQvfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert them to numpy arrays\n",
        "X = X.values\n",
        "Y = Y.values\n",
        "print(f'X = {X}')\n",
        "print(f'Y = {Y}')"
      ],
      "metadata": {
        "id": "qu7s8a-0RZDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To split the dataset into train and test dataset, we need scikit learn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "GGK-7fnKRbXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size = 0.2, random_state = 41)"
      ],
      "metadata": {
        "id": "ksgDtZo5SYOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert features to float tensors\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)"
      ],
      "metadata": {
        "id": "m114PiBiSoRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Long Tensor = 64 bit integers\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)"
      ],
      "metadata": {
        "id": "aqDCpRs2S4Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Error function to measure the prediction error\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
        "\n",
        "# lower the Learning rate, longer it will take to train."
      ],
      "metadata": {
        "id": "i4oAe47xTB88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train our model\n",
        "# 1 Epoch is 1 run through all the data\n",
        "epochs = 100\n",
        "losses = []\n",
        "for i in range(epochs):\n",
        "  # Process forward and predict\n",
        "  y_pred = model.forward(X_train)\n",
        "\n",
        "  # Calculate the error in prediction\n",
        "  loss = criterion(y_pred,y_train)\n",
        "\n",
        "  #Keep track of the loss per epoch\n",
        "  losses.append(loss.detach().numpy())\n",
        "\n",
        "  # Print every 10th epoch\n",
        "  if i % 10==0:\n",
        "    print(f\"Epoch : {i}, Loss : {loss}\")\n",
        "\n",
        "  # Back propagation\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "mEDWZmNbT35P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss across epochs\n",
        "plt.plot(range(epochs),losses)\n",
        "plt.ylabel('Losses')\n",
        "plt.xlabel('Epochs')\n"
      ],
      "metadata": {
        "id": "8owpFWfXUH98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tutorial 7 : Evaluate the test set**"
      ],
      "metadata": {
        "id": "1Mte8ZMAcmTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Model on the test dataset (do one pass through, wihtout back-propagation)\n",
        "with torch.no_grad(): # Turn off back propagation\n",
        "  y_eval = model.forward(X_test)\n",
        "  loss = criterion(y_eval, y_test)\n"
      ],
      "metadata": {
        "id": "QIa-HroxYmwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "id": "qIYb7myPaIys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at how the NN did on test data\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(X_test):\n",
        "    y_val = model.forward(data)\n",
        "\n",
        "    print(f'{i+1}.) {str(y_val)} \\t {y_test[i]} \\t {y_val.argmax().item()}')\n",
        "\n",
        "    # Correct or not\n",
        "    if y_val.argmax().item() == y_test[i]:\n",
        "      correct+=1\n",
        "\n",
        "print(f'We got {correct} correct!')"
      ],
      "metadata": {
        "id": "jhYRnF3BaKFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tutorial 8 : Evaluate the model on a NEW (Validation set)**"
      ],
      "metadata": {
        "id": "JS8uUkExddFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new data point\n",
        "new_iris = torch.tensor([4.7,3.2,1.3,0.2])"
      ],
      "metadata": {
        "id": "9HvRA3CoawKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run it through the model\n",
        "with torch.no_grad():\n",
        "  y_eval = model(new_iris)\n",
        "\n",
        "print(f'Prediction is {y_eval.argmax().item()}')"
      ],
      "metadata": {
        "id": "3-rrEeOwdwek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tutorial 9: Save and Load the NN model**"
      ],
      "metadata": {
        "id": "SubKSNeHfGev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save our NN Model\n",
        "torch.save(model.state_dict(),'my_simple_iris_NN.pt')"
      ],
      "metadata": {
        "id": "4oSttFxJeNWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How to load the saved model\n",
        "new_model = Model()\n",
        "new_model.load_state_dict(torch.load('my_simple_iris_NN.pt'))"
      ],
      "metadata": {
        "id": "tEJN3GvLfrL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to check if the correct model has loaded\n",
        "new_model.eval()"
      ],
      "metadata": {
        "id": "9X5KXWqEf6wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SRy4qLIUf-Tq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}